{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed96cc9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cec5d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for google.colab:colab:bd3cb750-a991-488f-afa3-305174c2e928"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "REPO_DIR = \"OT1-APITS\"\n",
    "\n",
    "# Check if we are running locally or need to clone\n",
    "if os.path.exists(\"../src\"):\n",
    "    print(\"Running locally (parent directory has src).\")\n",
    "    REPO_ROOT = \"..\"\n",
    "elif os.path.exists(\"src\"):\n",
    "    print(\"Running locally (current directory has src).\")\n",
    "    REPO_ROOT = \".\"\n",
    "else:\n",
    "    print(f\"Local src not found. Checking for clone in {REPO_DIR}...\")\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        print(\"Cloning repo...\")\n",
    "        !git clone https://github.com/Samsam19191/OT1-APITS.git {REPO_DIR}\n",
    "    else:\n",
    "        print(f\"Repo already cloned. Pulling latest...\")\n",
    "        !cd {REPO_DIR} && git pull\n",
    "    REPO_ROOT = REPO_DIR\n",
    "\n",
    "# Add to path\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.append(os.path.abspath(REPO_ROOT))\n",
    "\n",
    "print(f\"Repository root: {REPO_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97328c94",
   "metadata": {},
   "source": [
    "## 2. Import Streaming Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from src.events import EventType, KeystrokeEvent, StreamingSession\n",
    "from src.keystroke_simulator import (\n",
    "    KeystrokeSimulator,\n",
    "    LoggingConsumer,\n",
    "    simulate_typing,\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413812e9",
   "metadata": {},
   "source": [
    "## 3. Basic Typing Simulation\n",
    "\n",
    "First, let's see how the simulator generates events for a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shared queue (this is the interface between Lizhi and Rémi)\n",
    "queue = asyncio.Queue()\n",
    "\n",
    "# Sample Text-to-SQL query\n",
    "sample_query = \"Show me all patients\"\n",
    "\n",
    "print(f\"Simulating typing: '{sample_query}'\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_demo():\n",
    "    \"\"\"Run producer and consumer concurrently.\"\"\"\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    # Create producer (Lizhi's simulator)\n",
    "    simulator = KeystrokeSimulator(\n",
    "        queue,\n",
    "        mean_delay_ms=100,      # Faster for demo\n",
    "        debounce_ms=200,        # Shorter debounce for demo\n",
    "        typo_rate=0.0,          # No typos for cleaner output\n",
    "    )\n",
    "    \n",
    "    # Create consumer (placeholder for Rémi's inference service)\n",
    "    consumer = LoggingConsumer(queue, verbose=True)\n",
    "    \n",
    "    # Run both concurrently\n",
    "    producer_task = asyncio.create_task(\n",
    "        simulator.simulate_typing(sample_query)\n",
    "    )\n",
    "    consumer_task = asyncio.create_task(consumer.run())\n",
    "    \n",
    "    # Wait for completion\n",
    "    await asyncio.gather(producer_task, consumer_task)\n",
    "    \n",
    "    return consumer.events, simulator.session\n",
    "\n",
    "# Run the demo\n",
    "events, session = await run_demo()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Total events: {len(events)}\")\n",
    "print(f\"Final text: '{session.current_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d748c",
   "metadata": {},
   "source": [
    "## 4. Event Analysis\n",
    "\n",
    "Let's analyze the event stream to understand the confirmation boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10772df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count events by type\n",
    "from collections import Counter\n",
    "\n",
    "event_counts = Counter(e.event_type.name for e in events)\n",
    "print(\"Event distribution:\")\n",
    "for event_type, count in event_counts.items():\n",
    "    print(f\"  {event_type}: {count}\")\n",
    "\n",
    "# Show FLUSH events (confirmation points)\n",
    "print(\"\\nFLUSH events (token confirmation points):\")\n",
    "for e in events:\n",
    "    if e.event_type == EventType.FLUSH:\n",
    "        print(f\"  [{e.timestamp_ms:.0f}ms] confirmed: '{e.confirmed_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a34cfa",
   "metadata": {},
   "source": [
    "## 5. Typing Simulation with Typos\n",
    "\n",
    "Real users make typos. The simulator can model this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_demo_with_typos():\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    simulator = KeystrokeSimulator(\n",
    "        queue,\n",
    "        mean_delay_ms=80,\n",
    "        typo_rate=0.1,  # 10% typo rate for demo\n",
    "    )\n",
    "    \n",
    "    consumer = LoggingConsumer(queue, verbose=True)\n",
    "    \n",
    "    query = \"Find patients with diabetes\"\n",
    "    print(f\"Simulating with typos: '{query}'\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    await asyncio.gather(\n",
    "        simulator.simulate_typing(query),\n",
    "        consumer.run()\n",
    "    )\n",
    "    \n",
    "    # Count typo corrections (CHAR_DELETE events)\n",
    "    deletes = sum(1 for e in consumer.events if e.event_type == EventType.CHAR_DELETE)\n",
    "    print(f\"\\nTypos corrected: {deletes}\")\n",
    "    print(f\"Final text: '{simulator.session.current_text}'\")\n",
    "\n",
    "await run_demo_with_typos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a26893",
   "metadata": {},
   "source": [
    "## 6. Multiple Queries from File\n",
    "\n",
    "Load sample queries and simulate typing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load sample queries\n",
    "queries_file = Path(REPO_ROOT) / \"data\" / \"sample_queries.txt\"\n",
    "\n",
    "if queries_file.exists():\n",
    "    queries = queries_file.read_text().strip().split('\\n')\n",
    "    queries = [q for q in queries if q and not q.startswith('#')]\n",
    "    print(f\"Loaded {len(queries)} sample queries:\")\n",
    "    for i, q in enumerate(queries[:5]):\n",
    "        print(f\"  {i+1}. {q}\")\n",
    "    if len(queries) > 5:\n",
    "        print(f\"  ... and {len(queries)-5} more\")\n",
    "else:\n",
    "    print(f\"Warning: {queries_file} not found\")\n",
    "    queries = [\"Show me all patients\", \"List products by revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae077776",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def benchmark_query(query: str):\n",
    "    \"\"\"Measure timing statistics for a single query.\"\"\"\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    simulator = KeystrokeSimulator(\n",
    "        queue,\n",
    "        mean_delay_ms=120,\n",
    "        debounce_ms=250,\n",
    "        typo_rate=0.02,\n",
    "    )\n",
    "    \n",
    "    consumer = LoggingConsumer(queue, verbose=False)\n",
    "    \n",
    "    await asyncio.gather(\n",
    "        simulator.simulate_typing(query),\n",
    "        consumer.run()\n",
    "    )\n",
    "    \n",
    "    # Calculate stats\n",
    "    flush_events = [e for e in consumer.events if e.event_type == EventType.FLUSH]\n",
    "    submit_time = next(\n",
    "        (e.timestamp_ms for e in consumer.events if e.event_type == EventType.SUBMIT),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'chars': len(query),\n",
    "        'total_events': len(consumer.events),\n",
    "        'flush_count': len(flush_events),\n",
    "        'typing_time_ms': submit_time,\n",
    "        'chars_per_sec': len(query) / (submit_time / 1000) if submit_time > 0 else 0,\n",
    "    }\n",
    "\n",
    "# Benchmark first 3 queries\n",
    "print(\"Benchmarking queries...\\n\")\n",
    "for query in queries[:3]:\n",
    "    stats = await benchmark_query(query)\n",
    "    print(f\"Query: '{stats['query'][:40]}...'\" if len(stats['query']) > 40 else f\"Query: '{stats['query']}'\")\n",
    "    print(f\"  Chars: {stats['chars']}, Events: {stats['total_events']}, Flushes: {stats['flush_count']}\")\n",
    "    print(f\"  Typing time: {stats['typing_time_ms']:.0f}ms, Speed: {stats['chars_per_sec']:.1f} chars/sec\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f6c27",
   "metadata": {},
   "source": [
    "## 7. Custom Consumer Template (For Rémi)\n",
    "\n",
    "This shows how Rémi should implement the inference service consumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fdc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.keystroke_simulator import EventConsumer\n",
    "from src.events import EventType, KeystrokeEvent\n",
    "\n",
    "class InferenceConsumer(EventConsumer):\n",
    "    \"\"\"\n",
    "    Template for Rémi's inference service.\n",
    "    \n",
    "    This consumer should:\n",
    "    1. On CHAR_ADD: Update text buffer, maybe tokenize speculatively\n",
    "    2. On CHAR_DELETE: Handle rollback (crop KV-cache if needed)\n",
    "    3. On FLUSH: Run forward pass to extend KV-cache with confirmed tokens\n",
    "    4. On SUBMIT: Finalize cache, start generation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, queue):\n",
    "        super().__init__(queue)\n",
    "        self.confirmed_text = \"\"\n",
    "        self.kv_cache_len = 0  # Placeholder for actual cache tracking\n",
    "    \n",
    "    async def handle_event(self, event: KeystrokeEvent):\n",
    "        if event.event_type == EventType.CHAR_ADD:\n",
    "            # Text buffer updated - could tokenize speculatively here\n",
    "            pass\n",
    "        \n",
    "        elif event.event_type == EventType.CHAR_DELETE:\n",
    "            # Check if we need to rollback KV-cache\n",
    "            if len(event.current_text) < len(self.confirmed_text):\n",
    "                # Need to crop cache - this is where cache.crop() would be called\n",
    "                print(f\"  [ROLLBACK] Would crop cache from '{self.confirmed_text}' to '{event.confirmed_text}'\")\n",
    "                self.confirmed_text = event.confirmed_text\n",
    "        \n",
    "        elif event.event_type == EventType.FLUSH:\n",
    "            # New tokens confirmed - run forward pass\n",
    "            new_confirmed = event.confirmed_text\n",
    "            if len(new_confirmed) > len(self.confirmed_text):\n",
    "                delta = new_confirmed[len(self.confirmed_text):]\n",
    "                print(f\"  [FORWARD] Would extend KV-cache with: '{delta}'\")\n",
    "                self.confirmed_text = new_confirmed\n",
    "        \n",
    "        elif event.event_type == EventType.SUBMIT:\n",
    "            # Final submission - align cache and start generation\n",
    "            print(f\"  [SUBMIT] Final text: '{event.current_text}'\")\n",
    "            print(f\"  [SUBMIT] Cache already has: '{self.confirmed_text}'\")\n",
    "            remaining = event.current_text[len(self.confirmed_text):]\n",
    "            if remaining:\n",
    "                print(f\"  [SUBMIT] Would process remaining: '{remaining}'\")\n",
    "            print(f\"  [SUBMIT] Ready to generate!\")\n",
    "\n",
    "print(\"InferenceConsumer template defined ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demo_inference_consumer():\n",
    "    \"\"\"Demo the inference consumer with a sample query.\"\"\"\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    simulator = KeystrokeSimulator(\n",
    "        queue,\n",
    "        mean_delay_ms=50,\n",
    "        debounce_ms=150,\n",
    "        typo_rate=0.0,\n",
    "    )\n",
    "    \n",
    "    consumer = InferenceConsumer(queue)\n",
    "    \n",
    "    query = \"Show patients\"\n",
    "    print(f\"Demo with InferenceConsumer: '{query}'\\n\")\n",
    "    \n",
    "    await asyncio.gather(\n",
    "        simulator.simulate_typing(query),\n",
    "        consumer.run()\n",
    "    )\n",
    "\n",
    "await demo_inference_consumer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6ecbd",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "### For Lizhi:\n",
    "- [ ] Add more realistic typing patterns (burst typing, thinking pauses)\n",
    "- [ ] Integrate with Riad's WebSocket frontend when ready\n",
    "- [ ] Test with various query complexities\n",
    "\n",
    "### For Rémi:\n",
    "- [ ] Implement `InferenceConsumer` with actual KV-cache operations\n",
    "- [ ] Use the validated patterns from `02_extension.py` and `03_cropping.py`\n",
    "- [ ] Handle tokenization of confirmed text\n",
    "\n",
    "### Interface Contract:\n",
    "- Queue: `asyncio.Queue[KeystrokeEvent]`\n",
    "- Events: `CHAR_ADD`, `CHAR_DELETE`, `FLUSH`, `SUBMIT`, `END`\n",
    "- Key fields: `current_text`, `confirmed_text`, `timestamp_ms`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
